{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zhma\\Projects\\deid\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorForTokenClassification\n",
    "from transformers import AutoModelForTokenClassification\n",
    "from utils import PreProcess\n",
    "import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wfumodel = './checkpoint-8290'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(wfumodel)\n",
    "tokenizer.model_max_length = 128\n",
    "model = AutoModelForTokenClassification.from_pretrained(wfumodel)\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''Atrium Health Carolinas Medical Center (CMC) is the flagship hospital of Atrium Health, which is distinguished throughout the Southeastern United States for its excellent patient care and medical expertise.\n",
    "CMC operates at 2 locations: CMC and Atrium Health Mercy. These locations are 1.3 miles apart.\n",
    "From modest beginnings in 1943, we have evolved into the largest hospital in the region and a world-class facility that offers a full range of services to the Charlotte community and beyond, with more than 1,100 physicians and providers specializing in all areas of medicine.\n",
    "CMC serves as the region’s only Level 1 trauma center and is an approved transplant center for heart, kidney, pancreas and liver. We also serve as one of North Carolina’s 5 Academic Medical Center Teaching Hospitals, providing residency training for more than 200 physicians in 15 specialties and serve as a regional campus for Wake Forest University School of Medicine, based in Winston-Salem, NC.\n",
    "Carolinas Medical Center has been named the number 1 Best Hospital in the Charlotte region by U.S. News & World Report for 7 years in a row. Also located at CMC is Levine Cancer Institute's academic and research headquarters, Carolinas Rehabilitation, ranked #1 in the Southeast and top 10 in the nation, and Levine Children's Hospital, consistently ranked as a Best Children's Hospital in multiple specialties by U.S. News & World Report for 16 years in a row.\n",
    "Carolinas Medical Center and its outpatient clinics, as well as Levine Children’s Hospital, Levine Cancer Institute and Atrium Health Mercy, are Magnet designated by the American Nurses Credentialing Center’s Magnet Recognition Program®.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\zhma\\Projects\\deid\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:759\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[1;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[0;32m    758\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor(value):\n\u001b[1;32m--> 759\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    761\u001b[0m     \u001b[38;5;66;03m# Removing this for now in favor of controlling the shape with `prepend_batch_axis`\u001b[39;00m\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;66;03m# # at-least2d\u001b[39;00m\n\u001b[0;32m    763\u001b[0m     \u001b[38;5;66;03m# if tensor.ndim > 2:\u001b[39;00m\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;66;03m#     tensor = tensor.squeeze(0)\u001b[39;00m\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;66;03m# elif tensor.ndim < 2:\u001b[39;00m\n\u001b[0;32m    766\u001b[0m     \u001b[38;5;66;03m#     tensor = tensor[None, :]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zhma\\Projects\\deid\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:721\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors.<locals>.as_tensor\u001b[1;34m(value, dtype)\u001b[0m\n\u001b[0;32m    720\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39marray(value))\n\u001b[1;32m--> 721\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: expected sequence of length 128 at dim 1 (got 96)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m inputs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverflow_to_sample_mapping\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m inputs\n",
      "File \u001b[1;32mc:\\Users\\zhma\\Projects\\deid\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2883\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[1;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2881\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[0;32m   2882\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[1;32m-> 2883\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2885\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[1;32mc:\\Users\\zhma\\Projects\\deid\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2989\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2969\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_encode_plus(\n\u001b[0;32m   2970\u001b[0m         batch_text_or_text_pairs\u001b[38;5;241m=\u001b[39mbatch_text_or_text_pairs,\n\u001b[0;32m   2971\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2986\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2987\u001b[0m     )\n\u001b[0;32m   2988\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2989\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2990\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2991\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2992\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2993\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2994\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2995\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2996\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2997\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2998\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2999\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3000\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3001\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3002\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3003\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3004\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3005\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3006\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3007\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3008\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zhma\\Projects\\deid\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3062\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode_plus\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   3052\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[0;32m   3053\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[0;32m   3054\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m   3055\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3059\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3060\u001b[0m )\n\u001b[1;32m-> 3062\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3063\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3065\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3072\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3073\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3074\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3075\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3076\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3077\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3080\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3081\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zhma\\Projects\\deid\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_fast.py:583\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._encode_plus\u001b[1;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_encode_plus\u001b[39m(\n\u001b[0;32m    562\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    563\u001b[0m     text: Union[TextInput, PreTokenizedInput],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    581\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BatchEncoding:\n\u001b[0;32m    582\u001b[0m     batched_input \u001b[38;5;241m=\u001b[39m [(text, text_pair)] \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;28;01melse\u001b[39;00m [text]\n\u001b[1;32m--> 583\u001b[0m     batched_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatched_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    603\u001b[0m     \u001b[38;5;66;03m# Return tensor is None, then we can remove the leading batch axis\u001b[39;00m\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;66;03m# Overflowing tokens are returned as a batch of output so we keep them in this case\u001b[39;00m\n\u001b[0;32m    605\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_tensors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_overflowing_tokens:\n",
      "File \u001b[1;32mc:\\Users\\zhma\\Projects\\deid\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_fast.py:559\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[0;32m    557\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_ids \u001b[38;5;129;01min\u001b[39;00m sanitized_tokens[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eventual_warn_about_too_long_sequence(input_ids, max_length, verbose)\n\u001b[1;32m--> 559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBatchEncoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43msanitized_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msanitized_encodings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zhma\\Projects\\deid\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:224\u001b[0m, in \u001b[0;36mBatchEncoding.__init__\u001b[1;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[0;32m    220\u001b[0m     n_sequences \u001b[38;5;241m=\u001b[39m encoding[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_sequences\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_sequences \u001b[38;5;241m=\u001b[39m n_sequences\n\u001b[1;32m--> 224\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zhma\\Projects\\deid\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:775\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[1;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[0;32m    770\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverflowing_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    771\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    772\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to create tensor returning overflowing tokens of different lengths. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    773\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease see if a fast version of this tokenizer is available to have this feature available.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    774\u001b[0m             ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m--> 775\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    776\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to create tensor, you should probably activate truncation and/or padding with\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    777\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpadding=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtruncation=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to have batched tensors with the same length. Perhaps your\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    778\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m features (`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` in this case) have excessive nesting (inputs type `list` where type `int` is\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    779\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expected).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    780\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected)."
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(text, truncation=True, return_overflowing_tokens=True, return_tensors='pt')\n",
    "inputs.pop('overflow_to_sample_mapping')\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TokenClassificationPipeline\n",
    "\n",
    "clf = TokenClassificationPipeline(model=model, tokenizer=tokenizer)\n",
    "# clf._sanitize_parameters(stride=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'LABEL_3',\n",
       "  'score': 0.50738233,\n",
       "  'word': 'atrium health',\n",
       "  'start': 73,\n",
       "  'end': 86},\n",
       " {'entity_group': 'LABEL_3',\n",
       "  'score': 0.9105699,\n",
       "  'word': 'atrium health mercy',\n",
       "  'start': 244,\n",
       "  'end': 263},\n",
       " {'entity_group': 'LABEL_1',\n",
       "  'score': 0.9588765,\n",
       "  'word': '1943',\n",
       "  'start': 328,\n",
       "  'end': 332},\n",
       " {'entity_group': 'LABEL_3',\n",
       "  'score': 0.4075527,\n",
       "  'word': 'charlotte',\n",
       "  'start': 461,\n",
       "  'end': 470},\n",
       " {'entity_group': 'LABEL_7',\n",
       "  'score': 0.7204126,\n",
       "  'word': 'north carolina',\n",
       "  'start': 732,\n",
       "  'end': 746},\n",
       " {'entity_group': 'LABEL_3',\n",
       "  'score': 0.7648039,\n",
       "  'word': 'academic medical center',\n",
       "  'start': 751,\n",
       "  'end': 774},\n",
       " {'entity_group': 'LABEL_7',\n",
       "  'score': 0.53567636,\n",
       "  'word': 'wake',\n",
       "  'start': 906,\n",
       "  'end': 910},\n",
       " {'entity_group': 'LABEL_3',\n",
       "  'score': 0.720823,\n",
       "  'word': 'forest university school of medicine',\n",
       "  'start': 911,\n",
       "  'end': 947},\n",
       " {'entity_group': 'LABEL_7',\n",
       "  'score': 0.9862631,\n",
       "  'word': 'winston - salem, nc',\n",
       "  'start': 958,\n",
       "  'end': 975},\n",
       " {'entity_group': 'LABEL_3',\n",
       "  'score': 0.9800748,\n",
       "  'word': 'carolinas medical center',\n",
       "  'start': 977,\n",
       "  'end': 1001},\n",
       " {'entity_group': 'LABEL_3',\n",
       "  'score': 0.8967767,\n",
       "  'word': 'cmc',\n",
       "  'start': 1134,\n",
       "  'end': 1137},\n",
       " {'entity_group': 'LABEL_3',\n",
       "  'score': 0.91594267,\n",
       "  'word': 'levine cancer institute',\n",
       "  'start': 1141,\n",
       "  'end': 1164},\n",
       " {'entity_group': 'LABEL_7',\n",
       "  'score': 0.5931925,\n",
       "  'word': 'carolinas rehabilitation',\n",
       "  'start': 1203,\n",
       "  'end': 1227},\n",
       " {'entity_group': 'LABEL_3',\n",
       "  'score': 0.7378831,\n",
       "  'word': \"levine children ' s hospital\",\n",
       "  'start': 1286,\n",
       "  'end': 1312},\n",
       " {'entity_group': 'LABEL_3',\n",
       "  'score': 0.97348434,\n",
       "  'word': 'carolinas medical center',\n",
       "  'start': 1439,\n",
       "  'end': 1463},\n",
       " {'entity_group': 'LABEL_3',\n",
       "  'score': 0.9843067,\n",
       "  'word': 'levine children ’ s hospital',\n",
       "  'start': 1503,\n",
       "  'end': 1529},\n",
       " {'entity_group': 'LABEL_3',\n",
       "  'score': 0.95637256,\n",
       "  'word': 'levine cancer institute',\n",
       "  'start': 1531,\n",
       "  'end': 1554},\n",
       " {'entity_group': 'LABEL_3',\n",
       "  'score': 0.6594444,\n",
       "  'word': 'atrium health mercy',\n",
       "  'start': 1559,\n",
       "  'end': 1578}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf(text, stride=16, ignore_labels=['LABEL_12'], aggregation_strategy='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wfu_dataset = datasets.load_dataset('wfudata', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = wfu_dataset['train'][0]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf(example['text'], stride=16, ignore_labels=['LABEL_12'], aggregation_strategy='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = wfu_dataset['train'][:128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = clf(examples['text'], stride=16, ignore_labels=['LABEL_12'], aggregation_strategy='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in results[1]:\n",
    "    if x['entity_group'] == 'LABEL_8':\n",
    "        print(x['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples['text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "\n",
    "fake_names = ['Boris Hughes',\n",
    "'Boris Davies',\n",
    "'Kylie Rees',\n",
    "'Benjamin Sutherland',\n",
    "'Stewart Bell',\n",
    "'Boris Gill',\n",
    "'Mary Hamilton',\n",
    "'Jonathan Terry',\n",
    "'Steven Black',\n",
    "'Felicity Rees']\n",
    "\n",
    "fake_names = cycle(fake_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(fake_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_name(text, result):\n",
    "    all_names = [x['word'] for x in result if x['entity_group'] == 'LABEL_8']\n",
    "    all_names = set(all_names)\n",
    "    mapping = {}\n",
    "    for name in all_names:\n",
    "        mapping[name] = next(fake_names)\n",
    "    new_text = ''\n",
    "    prev_end = 0\n",
    "    for x in result:\n",
    "        if x['entity_group'] == 'LABEL_8':\n",
    "            start, end = x['start'], x['end']\n",
    "            fake_name = mapping[x['word']]\n",
    "            new_text = new_text + text[prev_end:end] + '[' + fake_name + ']'\n",
    "            prev_end = end\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Referring MD: Eagle Fam Medicine[Boris Gill], Bra*   PCP: Aaron Stanford Morrow[Jonathan Terry], MD   Identification: 1711219  Chief Complaint:   Chief Complaint   Patient presents with    Follow-up        PATIENT SUMMARY:  Susan Jane Isbell[Steven Black] is a 63 y.o. female with the onset of a left hand resting tremor in 2011.     She was first seen here in October of 2012. Her exam showed a left hand resting tremor, bradykinesia and rigidity worse on the left. Her symptoms were consistent with idiopathic parkinson&apos;s disease. After some discussion of her treatment options, she said she was primarily interested in improving her tremor. She started artane, which was titrated up to 2 mg twice daily. At first f/u she reported tremor has improved 85 percent since beginning Artane. Reported most concerning symptoms as cognitive. Has difficulty with word finding, more difficulty doing crossword puzzles and difficulty mult-tasking. She had always functioned at a high level and the change was distressing to her.     She had been under a significant amount of stress from 2010 to 2012. Her husband passed away from a medical accident, she lost her job of 30 years (customer service manager with AT&amp;T), and she is now living with her 88 year old father and caring for him. Antidepressants/mood stabilizers impoved her mood. She noticed the most improvement with the addition of Viibryd (an SSRI). In the mid-80s she had a serious car accident with loss of consciousness and amnesia for the day&apos;s events. After the accident, she saw a neuropsychologist for memory problems.     Impression from neuropsychological testing in April 2013:    Very significant current distress in the form of anxiety and (primarily cognitive and behavioral) depressive features. Cognition typically places in the upper quartile. Consistent with PD, there is evidence of mild slowing, a personal weakness in appreciating the visual Gestalt, and subtle visually-based inattention/impulsivity. Aligning with psychologist and pharmacological intervention were recommended as well as physical exercise and building a social support network.     Current Movement Disorder Medication:  Mirapex 1mg TID    Changes Made in Movement Disorder Medication:  Resume Artane 2mg BID    Subjective:     Susan Jane Isbell[Steven Black] is a 63 y.o. female with parkinson&apos;s disease who was last seen by Dr. Ihtsham Haq[Felicity Rees] on 5/22/14.     She is unaccompanied in the office today. At last visit, patient had had a slight worsening of her UPDRS and Mirapex was prescribed. She reports she had some nausea and possibly corner of the eye hallucinations when she first started taking the medication, but this has improved. Denies impulsivity, leg swelling, excessive sleepiness. She has not noticed any improvement in the tremor. She stopped the artane as of last visit, though it does not appear it was intended for her to do so. She says she felt she had more word finding difficulties while taking Artane, but she felt Artane gave her better tremor control. She rarely has issues with her balance. No falls.    Review of Systems:  A complete ROS was performed with pertinent positives/negatives noted in the HPI. The remainder of the ROS are negative.      The following portions of the patient&apos;s history were reviewed and updated as appropriate: allergies, current medications and problem list.    Patient Active Problem List   Diagnosis    Headache    Depression    Tremor     Past Medical History   Diagnosis Date    Headache      migraines    Depression      Past Surgical History   Procedure Laterality Date    Lumbar fusion       Hysterectomy      Bowel resection       Current Outpatient Prescriptions   Medication Sig    ALPRAZolam (XANAX) 1 MG tablet Take 1 mg by mouth nightly as needed.      calcium-vitamin D 500 mg(1,250mg) -200 unit per tablet Take 1 tablet by mouth daily.    cyanocobalamin (VITAMIN B-12) 1,000 mcg/mL injection Inject 1,000 mcg into the muscle every 30 (thirty) days.      lactobacillus rhamnosus, GG, (CULTURELLE) 10 billion cell capsule Take 1 capsule by mouth daily.    lamoTRIgine (LAMICTAL) 200 MG tablet Take 200 mg by mouth daily.      minocycline (MINOCIN,DYNACIN) 100 MG capsule Take 100 mg by mouth daily.    pramipexole (MIRAPEX) 1 MG tablet Take 1 tablet (1 mg total) by mouth 3 times daily.    traZODone (DESYREL) 100 MG tablet Take 100 mg by mouth nightly.      vilazodone (VIIBRYD) 20 mg Tab Take 20 mg by mouth daily.      ALMOTRIPTAN MALATE (AXERT ORAL) Take by mouth as needed.      doxycycline (ORACEA) 40 mg capsule Take 40 mg by mouth as needed.      oxaprozin (DAYPRO) 600 mg tablet Take 1,200 mg by mouth as needed.    pramipexole (MIRAPEX) 0.25 MG tablet Take 3 tablets (0.75 mg total) by mouth 3 times daily. Increase to this dose over 4 weeks as directed.    trihexyphenidyl (ARTANE) 2 MG tablet Take 1 tablet (2 mg total) by mouth 2 times daily with meals.     No Known Allergies     Objective:     Blood pressure 106/65, pulse 71, resp. rate 14, weight 58.786 kg (129 lb 9.6 oz).     Unified Parkinson&apos;s Disease Rating Scale (UPDRS) Motor Examination    Examination Treatment States    Dopa/Agonist Medications: On   Visit Type: General Followup     UPDRS Motor Examination  18. Speech: 0=Normal   19. Facial Expression: 1=Minimal hypomimia, could be normal &quot;Poker Face&quot;   20. Rest Tremor:          a. Face, Lips, Chin: 0=Absent         b. Right Hand: 1=Slight and infrequently present         c  Left Hand: 0=Absent         d. Right Leg: 0=Absent         e. Left Leg: 0=Absent    21. Action or postural tremor of the hands:          a. Right Hand 0=Absent         b. Left Hand 0=Absent   22. Rigidity:          a. Neck: 0=Absent         b. Right Upper Extremity: 1=Slight or detectable only when activated by mirror or other movements         c. Left Upper Extremity: 1=Slight or detectable only when activated by mirror or other movements         d. Right Lower Extremity: 2=Mild to moderate         e. Left Lower Extremity: 1=Slight or detectable only when activated by mirror or other movements   23. Finger Taps          a. Right Hand: 1=Mild slowing and/or reduction in amplitude         b. Left Hand: 1=Mild slowing and/or reduction in amplitude   24. Hand Movements          a. Right Hand 0=Normal         b. Left Hand 1=Mild slowing and/or reduction in amplitude   25. Rapid Alternating Movement          a. Right Hand 0=Normal         b. Left Hand 0=Normal   26. Leg Agility          a. Right Leg 0=Normal         b. Left Leg 1=Mild slowing and/or reduction in amplitude   27. Arising From Chair: 0=Normal     28. Posture: 0=Normal erect   29. Gait: 0=Normal   30: Postural Stability: 0=Normal   31: Body Bradykinesia and Hypokinesia: 2=Mild degree of slowness and poverty of movement which is definitely abnormal. Alternately some reduced amplitude        Total Motor Examination: 13     Previous UPDRS Score: 19     Assessment/Plan:     Susan Jane Isbell[Steven Black] is a 63 y.o. female with tremor predominant parkinson&apos;s disease. She has noticed no improvement in tremor since starting treatment with Mirapex.      Resume low-dose artane for tremor   If this causes a return of word finding difficulties, artane will be stopped and we will try increasing Mirapex.    If neither of these measures provide tremor improvement, we will initiate treatment with Sinemet    Follow up with Dr. Ihtsham Haq[Felicity Rees] in December  Pt was asked to call the clinic with any questions/concerns in the meantime.      QUALITY MEASURES   Patient was interviewed and screened for depression, falls, speech difficulties, hallucinations, impulsive behavior, cognitive difficulties and medication related side effects. Patient screened negative for all of the above except as noted above. Need for speech or physical therapy was assessed. Value of exercise was reemphasized.    A total of 30 minutes was spent face to face with the patient, more than half of which was spent in counseling, patient education, discussing medications and what to expect in future.       Sincerely,    Electronically signed by: Jennifer LeAnn Green[Mary Hamilton]\n"
     ]
    }
   ],
   "source": [
    "print(replace_name(examples['text'][1], results[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Referring MD: Eagle Fam Medicine, Bra*   PCP: Aaron Stanford Morrow, MD   Identification: 1711219  Chief Complaint:   Chief Complaint   Patient presents with    Follow-up        PATIENT SUMMARY:  Susan Jane Isbell is a 63 y.o. female with the onset of a left hand resting tremor in 2011.     She was first seen here in October of 2012. Her exam showed a left hand resting tremor, bradykinesia and rigidity worse on the left. Her symptoms were consistent with idiopathic parkinson&apos;s disease. After some discussion of her treatment options, she said she was primarily interested in improving her tremor. She started artane, which was titrated up to 2 mg twice daily. At first f/u she reported tremor has improved 85 percent since beginning Artane. Reported most concerning symptoms as cognitive. Has difficulty with word finding, more difficulty doing crossword puzzles and difficulty mult-tasking. She had always functioned at a high level and the change was distressing to her.     She had been under a significant amount of stress from 2010 to 2012. Her husband passed away from a medical accident, she lost her job of 30 years (customer service manager with AT&amp;T), and she is now living with her 88 year old father and caring for him. Antidepressants/mood stabilizers impoved her mood. She noticed the most improvement with the addition of Viibryd (an SSRI). In the mid-80s she had a serious car accident with loss of consciousness and amnesia for the day&apos;s events. After the accident, she saw a neuropsychologist for memory problems.     Impression from neuropsychological testing in April 2013:    Very significant current distress in the form of anxiety and (primarily cognitive and behavioral) depressive features. Cognition typically places in the upper quartile. Consistent with PD, there is evidence of mild slowing, a personal weakness in appreciating the visual Gestalt, and subtle visually-based inattention/impulsivity. Aligning with psychologist and pharmacological intervention were recommended as well as physical exercise and building a social support network.     Current Movement Disorder Medication:  Mirapex 1mg TID    Changes Made in Movement Disorder Medication:  Resume Artane 2mg BID    Subjective:     Susan Jane Isbell is a 63 y.o. female with parkinson&apos;s disease who was last seen by Dr. Ihtsham Haq on 5/22/14.     She is unaccompanied in the office today. At last visit, patient had had a slight worsening of her UPDRS and Mirapex was prescribed. She reports she had some nausea and possibly corner of the eye hallucinations when she first started taking the medication, but this has improved. Denies impulsivity, leg swelling, excessive sleepiness. She has not noticed any improvement in the tremor. She stopped the artane as of last visit, though it does not appear it was intended for her to do so. She says she felt she had more word finding difficulties while taking Artane, but she felt Artane gave her better tremor control. She rarely has issues with her balance. No falls.    Review of Systems:  A complete ROS was performed with pertinent positives/negatives noted in the HPI. The remainder of the ROS are negative.      The following portions of the patient&apos;s history were reviewed and updated as appropriate: allergies, current medications and problem list.    Patient Active Problem List   Diagnosis    Headache    Depression    Tremor     Past Medical History   Diagnosis Date    Headache      migraines    Depression      Past Surgical History   Procedure Laterality Date    Lumbar fusion       Hysterectomy      Bowel resection       Current Outpatient Prescriptions   Medication Sig    ALPRAZolam (XANAX) 1 MG tablet Take 1 mg by mouth nightly as needed.      calcium-vitamin D 500 mg(1,250mg) -200 unit per tablet Take 1 tablet by mouth daily.    cyanocobalamin (VITAMIN B-12) 1,000 mcg/mL injection Inject 1,000 mcg into the muscle every 30 (thirty) days.      lactobacillus rhamnosus, GG, (CULTURELLE) 10 billion cell capsule Take 1 capsule by mouth daily.    lamoTRIgine (LAMICTAL) 200 MG tablet Take 200 mg by mouth daily.      minocycline (MINOCIN,DYNACIN) 100 MG capsule Take 100 mg by mouth daily.    pramipexole (MIRAPEX) 1 MG tablet Take 1 tablet (1 mg total) by mouth 3 times daily.    traZODone (DESYREL) 100 MG tablet Take 100 mg by mouth nightly.      vilazodone (VIIBRYD) 20 mg Tab Take 20 mg by mouth daily.      ALMOTRIPTAN MALATE (AXERT ORAL) Take by mouth as needed.      doxycycline (ORACEA) 40 mg capsule Take 40 mg by mouth as needed.      oxaprozin (DAYPRO) 600 mg tablet Take 1,200 mg by mouth as needed.    pramipexole (MIRAPEX) 0.25 MG tablet Take 3 tablets (0.75 mg total) by mouth 3 times daily. Increase to this dose over 4 weeks as directed.    trihexyphenidyl (ARTANE) 2 MG tablet Take 1 tablet (2 mg total) by mouth 2 times daily with meals.     No Known Allergies     Objective:     Blood pressure 106/65, pulse 71, resp. rate 14, weight 58.786 kg (129 lb 9.6 oz).     Unified Parkinson&apos;s Disease Rating Scale (UPDRS) Motor Examination    Examination Treatment States    Dopa/Agonist Medications: On   Visit Type: General Followup     UPDRS Motor Examination  18. Speech: 0=Normal   19. Facial Expression: 1=Minimal hypomimia, could be normal &quot;Poker Face&quot;   20. Rest Tremor:          a. Face, Lips, Chin: 0=Absent         b. Right Hand: 1=Slight and infrequently present         c  Left Hand: 0=Absent         d. Right Leg: 0=Absent         e. Left Leg: 0=Absent    21. Action or postural tremor of the hands:          a. Right Hand 0=Absent         b. Left Hand 0=Absent   22. Rigidity:          a. Neck: 0=Absent         b. Right Upper Extremity: 1=Slight or detectable only when activated by mirror or other movements         c. Left Upper Extremity: 1=Slight or detectable only when activated by mirror or other movements         d. Right Lower Extremity: 2=Mild to moderate         e. Left Lower Extremity: 1=Slight or detectable only when activated by mirror or other movements   23. Finger Taps          a. Right Hand: 1=Mild slowing and/or reduction in amplitude         b. Left Hand: 1=Mild slowing and/or reduction in amplitude   24. Hand Movements          a. Right Hand 0=Normal         b. Left Hand 1=Mild slowing and/or reduction in amplitude   25. Rapid Alternating Movement          a. Right Hand 0=Normal         b. Left Hand 0=Normal   26. Leg Agility          a. Right Leg 0=Normal         b. Left Leg 1=Mild slowing and/or reduction in amplitude   27. Arising From Chair: 0=Normal     28. Posture: 0=Normal erect   29. Gait: 0=Normal   30: Postural Stability: 0=Normal   31: Body Bradykinesia and Hypokinesia: 2=Mild degree of slowness and poverty of movement which is definitely abnormal. Alternately some reduced amplitude        Total Motor Examination: 13     Previous UPDRS Score: 19     Assessment/Plan:     Susan Jane Isbell is a 63 y.o. female with tremor predominant parkinson&apos;s disease. She has noticed no improvement in tremor since starting treatment with Mirapex.      Resume low-dose artane for tremor   If this causes a return of word finding difficulties, artane will be stopped and we will try increasing Mirapex.    If neither of these measures provide tremor improvement, we will initiate treatment with Sinemet    Follow up with Dr. Ihtsham Haq in December  Pt was asked to call the clinic with any questions/concerns in the meantime.      QUALITY MEASURES   Patient was interviewed and screened for depression, falls, speech difficulties, hallucinations, impulsive behavior, cognitive difficulties and medication related side effects. Patient screened negative for all of the above except as noted above. Need for speech or physical therapy was assessed. Value of exercise was reemphasized.    A total of 30 minutes was spent face to face with the patient, more than half of which was spent in counseling, patient education, discussing medications and what to expect in future.       Sincerely,    Electronically signed by: Jennifer LeAnn Green, PA-C 7/23/2014 3:12 PM   Movement Disorders Center  Outpatient Neurology       \n"
     ]
    }
   ],
   "source": [
    "print(examples['text'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mresult\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
